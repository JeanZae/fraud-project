import pandas as pd
from sqlalchemy import create_engine, inspect
import os
import sys
from tqdm import tqdm
import psycopg2
import psycopg2.extras
import csv
from typing import Optional, Tuple

def load_data():

    DB_USR_NAME = os.getenv('DB_USR_NAME')
    DB_PWD = os.getenv('DB_PWD')
    DB_NAME = os.getenv('DB_NAME')
    DB_HOST = os.getenv('DB_HOST', 'db')
    DB_PORT = os.getenv('DB_PORT', '5432')

    # –°—Ç—Ä–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è:
    DATABASE_URL = f"postgresql://{DB_USR_NAME}:{DB_PWD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    
    # 3. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
    engine = create_engine(DATABASE_URL)

# engine test
    # try:
    #     with engine.connect() as connection:
    #         print('sucs')
    # except Exception as e:
    #     print("fail", e)

    inspector = inspect(engine)
    
    if inspector.has_table('transactions'):
        try:
            count = pd.read_sql('SELECT COUNT(*) as cnt FROM transactions;', engine)
            print(count)
            rows_in_db = count.iloc[0]['cnt']
            if rows_in_db > 0:
                print(f"‚úì –í —Ç–∞–±–ª–∏—Ü–µ —É–∂–µ –µ—Å—Ç—å {rows_in_db:,} —Å—Ç—Ä–æ–∫. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
                return engine
            else:
                print("–¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞—è, –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
        except Exception as e:
            raise(e)
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É...")

    # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º CSV
    CSV_PATH = os.getenv('CSV_PATH')
    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {CSV_PATH}...")
    
    try:
        df = pd.read_csv(CSV_PATH)
        print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")
        sys.exit(1)
    
    # 5. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –ë–î
    try:
        print("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö...", flush=True)
        chunk_size = 500000
        total_rows = 0

        for chunk in tqdm(pd.read_csv(CSV_PATH, chunksize=chunk_size), desc="–ó–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î"):
            chunk.to_sql('transactions', engine, if_exists='replace', index=False)
            total_rows += len(chunk)
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {total_rows:,} —Å—Ç—Ä–æ–∫", flush=True)

        print(f"‚úì –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {total_rows:,} —Å—Ç—Ä–æ–∫", flush=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º
        count = pd.read_sql('SELECT COUNT(*) as cnt FROM transactions', engine)
        print(f"–í —Ç–∞–±–ª–∏—Ü–µ —Ç–µ–ø–µ—Ä—å {count.iloc[0]['cnt']} —Å—Ç—Ä–æ–∫")
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î: {e}")
        sys.exit(1)


def load_ps2():

    DB_USR_NAME = os.getenv('DB_USR_NAME')
    DB_PWD = os.getenv('DB_PWD')
    DB_NAME = os.getenv('DB_NAME')
    DB_HOST = os.getenv('DB_HOST', 'db')
    DB_PORT = os.getenv('DB_PORT', '5432')
    CSV_PATH = os.getenv('CSV_PATH')

    if not os.path.exists(CSV_PATH):
        print(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {CSV_PATH}")
        sys.exit(1)

    print("üîó –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")

    try:
        conn = psycopg2.connect(
            dbname=DB_NAME,
            user=DB_USR_NAME,
            password=DB_PWD,
            host=DB_HOST,
            port=DB_PORT,
            connect_timeout=10,
            # client_encoding='utf8',
            application_name='data_loader'  # –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ pg_stat_activity
        )

        cur = conn.cursor()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        cur.execute("""
            SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name = 'transactions'
            )
        """)

        table_exists = cur.fetchone()[0]

        if table_exists:
            # –¢–∞–±–ª–∏—Ü–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
            cur.execute("SELECT COUNT(*) FROM transactions")
            row_count = cur.fetchone()[0]
            
            if row_count > 0:
                print(f"–¢–∞–±–ª–∏—Ü–∞ 'transactions' —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç {row_count:,} —Å—Ç—Ä–æ–∫")
                print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
                return
            else:
                print("–¢–∞–±–ª–∏—Ü–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ –ø—É—Å—Ç–∞—è. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
                load_csv_data(cur, CSV_PATH)
        else:
            print("–¢–∞–±–ª–∏—Ü–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
            create_table_from_csv(cur, CSV_PATH)
            print("–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
            load_csv_data(cur, CSV_PATH)
        conn.commit()


        cur.execute("SELECT COUNT(*) FROM transactions")
        final_count = cur.fetchone()[0]
        print(f"{final_count:,} —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ")
        cur.close()

    except Exception as e:
        if conn:
            conn.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise
    finally:
        if conn:
            conn.close()




def create_table_from_csv(cursor, csv_path: str):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ CSV —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏"""
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        headers = [h.strip() for h in next(reader)]  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    
    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
    column_types = {}
    
    for header in headers:
        header_lower = header.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ –∏–º–µ–Ω–∏ –∫–æ–ª–æ–Ω–∫–∏
        if header_lower == 'step':
            col_type = 'INTEGER'
        elif header_lower == 'type':
            col_type = 'VARCHAR(20)'
        elif 'amount' in header_lower or 'balance' in header_lower:
            col_type = 'NUMERIC'  # 12 —Ü–∏—Ñ—Ä –≤—Å–µ–≥–æ, 2 –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
        elif 'name' in header_lower:
            col_type = 'VARCHAR(50)'
        elif 'isfraud' in header_lower or 'isflaggedfraud' in header_lower:
            col_type = 'BOOLEAN'
        else:
            col_type = 'TEXT'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
        column_types[header] = col_type
    
    # –°–æ–∑–¥–∞–µ–º SQL –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
    columns_def = []
    for header in headers:
        col_type = column_types[header]
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ —Å–ª—É—á–∞–π —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
        columns_def.append(f'"{header}" {col_type}')
    
    create_sql = f"""
        CREATE TABLE transactions (
            id BIGSERIAL PRIMARY KEY,
            {", ".join(columns_def)},
            loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """
    
    cursor.execute(create_sql)
    print(f"–°–æ–∑–¥–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å {len(headers)} –∫–æ–ª–æ–Ω–∫–∞–º–∏")
    
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–∞—Ö
    print("–¢–∏–ø—ã –∫–æ–ª–æ–Ω–æ–∫:")
    for header, col_type in column_types.items():
        print(f"  - {header}: {col_type}")


def load_csv_data(cursor, csv_path: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ç–∞–±–ª–∏—Ü—É"""
    with open(csv_path, 'r', encoding='utf-8') as f:
        # –°–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        reader = csv.reader(f)
        headers = next(reader)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
        f.seek(0)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º COPY –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        copy_sql = """
            COPY transactions({columns}) 
            FROM STDIN 
            WITH (
                FORMAT CSV,
                HEADER TRUE,
                DELIMITER ',',
                NULL '',
                QUOTE '"',
                ESCAPE '\\',
                ENCODING 'UTF8'
            )
        """.format(columns=", ".join([f'"{h}"' for h in headers]))
        
        cursor.copy_expert(copy_sql, f)
    
    print("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —á–µ—Ä–µ–∑ COPY")


def load_to_parquet():
    cache_path = '/data/cache/transactions.parquet'
    if os.path.exists(cache_path):
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫—ç—à–∞...")
        try:
            df = pd.read_parquet(cache_path)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ None –∏ –Ω–µ –ø—É—Å—Ç–æ–π DataFrame
            if df is None:
                raise ValueError("pd.read_parquet –≤–µ—Ä–Ω—É–ª None")
            if df.empty:
                print("–ö—ç—à —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É—Å—Ç–æ–π DataFrame. –£–¥–∞–ª—è–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–Ω–æ–≤–æ.")
                os.remove(cache_path)
            else:
                print(f"–ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω, —Ñ–æ—Ä–º–∞: {df.shape}")
                return df
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫—ç—à–∞: {e}. –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π —Ñ–∞–π–ª.")
            try:
                os.remove(cache_path)
            except OSError:
                pass
    
    # –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ë–î
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –ë–î...")

    DB_USR_NAME = os.getenv('DB_USR_NAME')
    DB_PWD = os.getenv('DB_PWD')
    DB_NAME = os.getenv('DB_NAME')
    DB_HOST = os.getenv('DB_HOST', 'db')
    DB_PORT = os.getenv('DB_PORT', '5432')
    CSV_PATH = os.getenv('CSV_PATH')

    print("üîó –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")

    conn = psycopg2.connect(
        dbname=DB_NAME,
        user=DB_USR_NAME,
        password=DB_PWD,
        host=DB_HOST,
        port=DB_PORT,
        connect_timeout=10,
        # client_encoding='utf8',
        application_name='data_loader'  # –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ pg_stat_activity
    )

    df = pd.read_sql('SELECT * FROM transactions', conn)
    conn.close()

    os.makedirs(os.path.dirname(cache_path), exist_ok=True)
    df.to_parquet(cache_path, engine='pyarrow')
    print(f"–î–∞–Ω–Ω—ã–µ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã –≤ {cache_path}")
    
    return df